{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb5a575-c922-4894-94c3-87eb37131525",
   "metadata": {},
   "source": [
    "# Data Analysis of Flux Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f18953-7ef1-4046-b324-54e0f613a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7966b801-2330-40aa-9f55-916cb51e2f0e",
   "metadata": {},
   "source": [
    "A numerical simulation creates datafile in the [Parquet file format](https://parquet.apache.org/documentation/latest/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9141ac-4d1f-48aa-abd0-c7e4fca489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"data/*.parquet\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ba68c8-d0ed-4ad7-8201-bb2f73f3fbbc",
   "metadata": {},
   "source": [
    "We can use `pd.read_parquet` to read the data and `pq.read_schema` to read the metadata.  For this set of simulations, the parameters `Pe` and `SS` are the only ones changing between simulations. We create a multidimensional Xarray dataset to hold the output from each experiment with the parameters serving as dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d9389-e46b-47f9-82f6-e054f1a91fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_data(file):\n",
    "    # load parquet file as pandas dataframe\n",
    "    df = pd.read_parquet(file)\n",
    "    # remove multi-index on column\n",
    "    df = df.droplevel(level=0, axis=1)\n",
    "    # convert to a Xarray Dataset\n",
    "    ds = xr.Dataset(df)\n",
    "\n",
    "    # metadata is also stored in the parquet file\n",
    "    def DictFilter(x,y):\n",
    "        \"\"\"Slice dict. Usage: dictfilter(originaldict, [dictkeystokeep])\"\"\"\n",
    "        return dict([ (i,x[i]) for i in x if i in set(y)])\n",
    "\n",
    "    schema = pq.read_schema(file)\n",
    "    metadata = json.loads(schema.metadata[b'metadata'])\n",
    "\n",
    "    mdata = metadata['updatedparameters'][0] if 'updatedparameters' in metadata.keys() else metadata['yaml'][0]\n",
    "    mdata = DictFilter(mdata, ['Mesh','Parameters'])\n",
    "    mdata.update({'Simulation': metadata['simulation']})\n",
    "\n",
    "    mesh_metadata = mdata['Mesh']\n",
    "    parameters_metadata = mdata['Parameters']\n",
    "    simulation_metadata = mdata['Simulation']\n",
    "\n",
    "    # Pull out variables that are changing between experiments\n",
    "    Pe = parameters_metadata['Pe']\n",
    "    SS = mesh_metadata['SS']\n",
    "\n",
    "    # Add new dimensions for the changing parameters\n",
    "    ds = ds.expand_dims(['Pe', 'SS'])\n",
    "    ds['Pe'] = [Pe]\n",
    "    ds['SS'] = [SS]\n",
    "\n",
    "    # remove those parameters from the shared list of parameters\n",
    "    del parameters_metadata['Pe']\n",
    "    del mesh_metadata['SS']\n",
    "    \n",
    "    # nx: None will not be storable in a NetCDF file. Remove it.\n",
    "    if 'nx' in mesh_metadata and mesh_metadata['nx'] is None:\n",
    "        del mesh_metadata['nx']\n",
    "    # NetCDF does not support boolean for attribute data type\n",
    "    if 'override' in mesh_metadata:\n",
    "        mesh_metadata['override'] = int(mesh_metadata['override'])\n",
    "        \n",
    "    ds = ds.assign_attrs(mesh_metadata)\n",
    "    ds = ds.assign_attrs(parameters_metadata)\n",
    "    ds = ds.assign_attrs(simulation_metadata)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abc722-c3ce-431e-9a4f-cf2454e6d184",
   "metadata": {},
   "source": [
    "As an example, here one of the data files transformed into a Xarray dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba679a8b-9b5f-4c6b-994f-5c23efc127cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_parquet_data(files[0])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f913ae4-61e9-481b-a193-a27b98a9e840",
   "metadata": {},
   "source": [
    "These datasets can be merged into one large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb3090-6cd4-4adc-b06d-f9db66a9d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([load_parquet_data(f) for f in files], combine_attrs='drop_conflicts') # combine_attrs='drop_conflicts' so that only common metadata is shown for collection of datasets\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40404bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When analyzing data it is important to know where each subset of the dataset comes from\n",
    "# That is, we need to be able to extract metadata for each individual simulation\n",
    "# Notice \"Attributes\" above is for the entire collection.\n",
    "# The problem is that we lost the attributes of individual datasets when we called xr.merge().\n",
    "\n",
    "# Example: select a single simulation from the complete dataset.\n",
    "# Any attributes that are unique to the data, such as 'timestamp' were lost.\n",
    "\n",
    "print('ACTUAL:', ds.sel(Pe=200, SS=1).attrs) # extracted from merged dataset\n",
    "print('EXPECTED:',load_parquet_data(files[0]).attrs) # from single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5e29f-8f83-46a3-a126-f1fcae8f6cbc",
   "metadata": {},
   "source": [
    "The NaNs are occuring because some simulations stopped earlier than others. This can be fixed by filling or padding the data.\n",
    "We can store the complete dataset as a single NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd79358-65e8-4354-9281-f0aff89c5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"data.nc\"):\n",
    "    os.remove(\"data.nc\")\n",
    "    \n",
    "ds.to_netcdf(\"data.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d3244-9339-41b5-9053-b472d6ad6cf2",
   "metadata": {},
   "source": [
    "For future analysis, we can just load this NetCDF file directly and skip the building of the NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf40bfa-b67e-4b5f-8dcf-646d217460ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"data.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7b683-5a07-4033-8be2-0194f79e226c",
   "metadata": {},
   "source": [
    "We can select the data from only one experiment by indexing by `Pe` or `SS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d1eed-fb6c-4618-b52c-322efa82b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(Pe=200, SS=1).plot.scatter(x=\"Time\", y=\"s1\", label='s1')\n",
    "ds.sel(Pe=200, SS=1).plot.scatter(x=\"Time\", y=\"s2\", label='s2')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Dimensional Flux')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c53133-779f-4d75-bb7f-49251aede6a2",
   "metadata": {},
   "source": [
    "But the real power comes with using `Pe` and `SS` as part of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc17fa-7aeb-4488-a816-8ee38da24b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.plot.scatter(x='Time', y='s1', hue='Pe', col='SS')\n",
    "ds.plot.scatter(x='Time', y='s2', hue='Pe', col='SS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b7664-ea1d-4cb4-a659-2db9c4bfe947",
   "metadata": {},
   "source": [
    "Or grouping by Pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890d8de-c443-494d-a47c-f8c60091acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.plot.scatter(x='Time', y='s1', hue='SS', col='Pe')\n",
    "ds.plot.scatter(x='Time', y='s2', hue='SS', col='Pe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3351a90-9099-497f-acc4-1481921a1a37",
   "metadata": {},
   "source": [
    "To summarize over all Pe and SS, we can calculate the maximum flux in Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5c9cb-8d0f-4110-ad27-2413d5b55325",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "ds.s1.max(dim='Time').plot(ax=ax[0])\n",
    "ax[0].set_title('s1')\n",
    "ds.s2.max(dim='Time').plot(ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d53f25-5e18-4cc2-87a3-70a6ad65a6ed",
   "metadata": {},
   "source": [
    "If you have the Holoviz package installed (hvplot) you can get some instant interactivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7fe1d6-84d3-4466-a1ae-ee91b0da5d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66546532-fb8e-433c-ade9-87e2b20a5612",
   "metadata": {},
   "source": [
    "Use the slider to change the value of SS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35e472-6c23-4bcf-91ff-c5c858fa3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = ds.hvplot.scatter(x='Time', y='s1', by='Pe')\n",
    "s2 = ds.hvplot.scatter(x='Time', y='s2', by='Pe')\n",
    "(s1+s2).cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c7fa0-c817-4a90-9ded-cf05a05232cc",
   "metadata": {},
   "source": [
    "Or the equilibrium fluxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8fbcb-daa8-471f-b673-063ead7a0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "equlibrium = ds.max(\"Time\")\n",
    "s1 = equlibrium.hvplot.heatmap(x='SS', y='Pe', C='s1')\n",
    "s2 = equlibrium.hvplot.heatmap(x='SS', y='Pe', C='s2') \n",
    "\n",
    "(s1+s2).cols(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
